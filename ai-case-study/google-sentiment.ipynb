{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc88b042-9d24-48fc-94a3-6009b4951e7b",
   "metadata": {},
   "source": [
    "# Multipool Google Sentiment Analysis\n",
    "\n",
    "this function will get data from google_result table\n",
    "and calculate the sentiment analysis. Result is store in google_result_sentiment\n",
    "\n",
    "crontab command\n",
    "* * * * * /home/haviz/multipool/ai-case-study/run-ai-sa-google.sh >> /home/haviz/multipool/ai-sa-google.log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0afb3-cd43-479c-a645-5eb16d589ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql.cursors\n",
    "import sqlalchemy as sa\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from sqlalchemy import create_engine, Column, Integer, String, MetaData, Table\n",
    "from sqlalchemy.sql import text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64d1af-b458-4c9e-9762-1d3d780b616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.util import deprecations\n",
    "deprecations.SILENCE_UBER_WARNING = True\n",
    "\n",
    "def execute_query(query, params=None):\n",
    "    # Set your PostgreSQL connection parameters\n",
    "    db_params = {\n",
    "        'host': '103.82.242.92',\n",
    "        'port': '5710',\n",
    "        'database': 'medols',\n",
    "        'user': 'postgres',\n",
    "        'password': 'FEWcTB3JIX5gK4T06c1MdkM9N2S8w9pb',\n",
    "    }\n",
    "\n",
    "    # Create a SQLAlchemy engine\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}\")\n",
    "\n",
    "    # Create a metadata object\n",
    "    metadata = MetaData(bind=engine)\n",
    "\n",
    "    # Example: Define your table\n",
    "    your_table = Table('your_table', metadata,\n",
    "                       Column('id', Integer, primary_key=True),\n",
    "                       Column('column1', String),\n",
    "                       Column('column2', String)\n",
    "                       )\n",
    "\n",
    "    # Create a session\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    try:\n",
    "        # Execute the query with optional parameters\n",
    "        result = session.execute(text(query), params)\n",
    "\n",
    "        # Check if the query is a SELECT query\n",
    "        is_select_query = result.returns_rows\n",
    "\n",
    "        if is_select_query:\n",
    "            # Fetch the data and return as a Pandas DataFrame\n",
    "            columns = result.keys()\n",
    "            fetched_data = result.fetchall()\n",
    "            df = pd.DataFrame(fetched_data, columns=columns)\n",
    "            # print(\"Fetched Data as DataFrame:\")\n",
    "            # print(df)\n",
    "            return df\n",
    "        else:\n",
    "            # Get the number of rows affected for non-SELECT queries\n",
    "            rows_affected = result.rowcount\n",
    "\n",
    "            # Commit the changes to the database for non-SELECT queries\n",
    "            session.commit()\n",
    "\n",
    "            print(f\"Query executed successfully. {rows_affected} rows affected.\")\n",
    "            return rows_affected\n",
    "    except Exception as e:\n",
    "        # Rollback changes if there's an error\n",
    "        session.rollback()\n",
    "        print(f\"Error executing query: {e}\")\n",
    "    finally:\n",
    "        # Close the session\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf0378-4165-46bd-abc9-05c3a9fe18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def stemming(comment):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    do = []\n",
    "    for w in comment:\n",
    "        dt = stemmer.stem(w)\n",
    "        do.append(dt)\n",
    "    d_clean = []\n",
    "    d_clean = \" \".join(do)\n",
    "    return d_clean\n",
    "    \n",
    "# function case folding\n",
    "def casefolding(comment):\n",
    "    comment = comment.lower()\n",
    "    comment = comment.strip(\" \")\n",
    "    comment = re.sub(r'[?|$|.|!_:\")(-+,]','',comment)\n",
    "    return comment\n",
    "\n",
    "def clean_up_tag(comment):\n",
    "    x_ret = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",comment).split())\n",
    "    return x_ret\n",
    "\n",
    "# Text Preprocessing, \n",
    "def text_preproc(strIn):\n",
    "    # case folding\n",
    "    strOut = strIn.lower()\n",
    "    \n",
    "    # remove numbers\n",
    "    strOut = re.sub(r\"\\d+\", \"\", strOut)\n",
    "    \n",
    "    # remote punctuation\n",
    "    strOut = strOut.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    \n",
    "    # remove whitspace\n",
    "    strOut = strOut.strip()\n",
    "    \n",
    "    # \n",
    "    strOut = re.sub('\\s+',' ',strOut)\n",
    "    return strOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a292a-3e97-4161-bcaf-1887c838ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_by_df(source_ds):\n",
    "    from tqdm import tqdm\n",
    "    pd.options.mode.chained_assignment = None \n",
    "\n",
    "    # we calculate sentiment for 'title' and 'description' column\n",
    "\n",
    "    # remove first\n",
    "    source_ds['title'] = source_ds['title'].apply(clean_up_tag)\n",
    "    source_ds['description'] = source_ds['description'].apply(clean_up_tag)\n",
    "\n",
    "\n",
    "    # skip stemming\n",
    "    source_ds['stemmed'] = source_ds['title']\n",
    "    source_ds['stemmed'] = source_ds['stemmed'].apply(casefolding)\n",
    "    source_ds['stemmed'] = source_ds['stemmed'].apply(text_preproc)\n",
    "\n",
    "    sw = stopwords.words('indonesian')\n",
    "    #tokenized\n",
    "    source_ds['tokenized_tweet'] = source_ds.apply(lambda row: nltk.word_tokenize(row['stemmed']), axis=1)\n",
    "\n",
    "    # apply stopword removal\n",
    "    source_ds['tokenized_tweet'] = source_ds.apply(lambda row: {w for w in row['tokenized_tweet'] if not w in sw}, axis=1)\n",
    "    sw = stopwords.words('indonesian')\n",
    "\n",
    "    #tokenized\n",
    "    source_ds['tokenized_tweet'] = source_ds.apply(lambda row: nltk.word_tokenize(row['stemmed']), axis=1)\n",
    "\n",
    "    # apply stopword removal\n",
    "    source_ds['tokenized_tweet'] = source_ds.apply(lambda row: {w for w in row['tokenized_tweet'] if not w in sw}, axis=1)\n",
    "\n",
    "    # Notes on return sentiment values\n",
    "    # 1 >> positif >> stay\n",
    "    # 2 >> negatif >> convert to -1\n",
    "    # 0 >> netral >> stay\n",
    "\n",
    "    # Create a new list and insert each element from the original list\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    list_text = source_ds['stemmed'].tolist()\n",
    "    new_list = []\n",
    "    for i in tqdm(range( len(list_text) )):\n",
    "        res = pipe(list_text[i])\n",
    "        #print(res)\n",
    "        new_list.append(res)\n",
    "\n",
    "    # Notes on return sentiment values\n",
    "    # 1 >> positif >> stay\n",
    "    # 2 >> negatif >> convert to -1\n",
    "    # 0 >> netral >> stay\n",
    "    # create a list of our conditions\n",
    "    for i in range(0, len(new_list)):\n",
    "        # print(new_list[i][0]['label'])\n",
    "        if new_list[i][0]['label'] == 'Positive':\n",
    "            new_list[i][0]['Value'] = 1\n",
    "        elif new_list[i][0]['label'] == 'Negative':\n",
    "            new_list[i][0]['Value'] = -1\n",
    "        elif new_list[i][0]['label'] == 'Neutral':\n",
    "            new_list[i][0]['Value'] = 0\n",
    "\n",
    "    for index, row in source_ds.iterrows():\n",
    "        source_ds.at[index,'Prediction'] = new_list[index][0]['label']\n",
    "\n",
    "    for index, row in source_ds.iterrows():\n",
    "        source_ds.at[index,'Prediction'] = new_list[index][0]['label']\n",
    "        source_ds.at[index,'Score'] = new_list[index][0]['score']\n",
    "        #source_ds.at[index,'Score'] = new_list[index][0]['Value']\n",
    "        \n",
    "    return source_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b5528-6ca4-411d-9b57-069e3a6d3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query 400 rows of data query data from table\n",
    "select_query = \"select * \\\n",
    "from google_result gr \\\n",
    "where google_result_id not in (select google_result_id from google_result_sentiment) \\\n",
    "order by google_result_id desc limit 500\"\n",
    "\n",
    "source_ds = execute_query(select_query)\n",
    "\n",
    "if len(source_ds) == 0:\n",
    "    # get out, nothing to do\n",
    "    print('Zero jobs, quitting now')\n",
    "    quit()\n",
    "    \n",
    "# source_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fe7d0-c005-45ad-8291-16c8bd9f7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds = process_by_df(source_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30b8a9-31bc-4bd6-a4da-7484686cac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d92f04-856f-49d7-ac4c-b10fb4516774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record result\n",
    "sentiment_class = 0\n",
    "\n",
    "# INSERT INTO public.google_result_sentiment (id, sentiment_category, score, google_result_id) VALUES(nextval('google_result_sentiment_id_seq'::regclass), 0, 0, 0);\n",
    "\n",
    "for index, row in res_ds.iterrows():\n",
    "    if row['Prediction'] == 'Positive':\n",
    "        sentiment_class = 1\n",
    "    elif row['Prediction'] == 'Negative':\n",
    "        sentiment_class = -1\n",
    "    else:\n",
    "        sentiment_class = 0\n",
    "        \n",
    "    # sql = \"INSERT INTO cekmedsos_database.ret_sentiment_result (job_id, tweet_id, sentiment_class) VALUES(%s, %s , %s);\" % (str(const_job_id), row['id_str'], str(sentiment_class))\n",
    "    sql = \"INSERT INTO public.google_result_sentiment (id, sentiment_category, score, google_result_id) VALUES(nextval('google_result_sentiment_id_seq'::regclass), %s, %s, %s);\" % (sentiment_class,row['Score'],row['google_result_id']) \n",
    "    #print(sql)\n",
    "    execute_query(sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
