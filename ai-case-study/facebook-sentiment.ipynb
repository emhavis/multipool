{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc88b042-9d24-48fc-94a3-6009b4951e7b",
   "metadata": {},
   "source": [
    "# Multipool Google Sentiment Analysis\n",
    "\n",
    "this function will get data from google_result table\n",
    "and calculate the sentiment analysis. Result is store in google_result_sentiment\n",
    "\n",
    "crontab command\n",
    "* * * * * /home/haviz/multipool/ai-case-study/run-ai-sa-google.sh >> /home/haviz/multipool/ai-sa-google.log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d0afb3-cd43-479c-a645-5eb16d589ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql.cursors\n",
    "import sqlalchemy as sa\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from sqlalchemy import create_engine, Column, Integer, String, MetaData, Table\n",
    "from sqlalchemy.sql import text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec64d1af-b458-4c9e-9762-1d3d780b616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.util import deprecations\n",
    "deprecations.SILENCE_UBER_WARNING = True\n",
    "\n",
    "def execute_query(query, params=None):\n",
    "    # Set your PostgreSQL connection parameters\n",
    "    db_params = {\n",
    "        'host': '98.98.117.105',\n",
    "        'port': '5432',\n",
    "        'database': 'medols',\n",
    "        'user': 'postgres',\n",
    "        'password': 'FEWcTB3JIX5gK4T06c1MdkM9N2S8w9pb',\n",
    "    }\n",
    "\n",
    "    # Create a SQLAlchemy engine\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}\")\n",
    "\n",
    "    # Create a metadata object\n",
    "    metadata = MetaData()\n",
    "\n",
    "    # Example: Define your table\n",
    "    your_table = Table('your_table', metadata,\n",
    "                       Column('id', Integer, primary_key=True),\n",
    "                       Column('column1', String),\n",
    "                       Column('column2', String)\n",
    "                       )\n",
    "\n",
    "    # Create a session\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    try:\n",
    "        # Execute the query with optional parameters\n",
    "        result = session.execute(text(query), params)\n",
    "\n",
    "        # Check if the query is a SELECT query\n",
    "        is_select_query = result.returns_rows\n",
    "\n",
    "        if is_select_query:\n",
    "            # Fetch the data and return as a Pandas DataFrame\n",
    "            columns = result.keys()\n",
    "            fetched_data = result.fetchall()\n",
    "            df = pd.DataFrame(fetched_data, columns=columns)\n",
    "            # print(\"Fetched Data as DataFrame:\")\n",
    "            # print(df)\n",
    "            return df\n",
    "        else:\n",
    "            # Get the number of rows affected for non-SELECT queries\n",
    "            rows_affected = result.rowcount\n",
    "\n",
    "            # Commit the changes to the database for non-SELECT queries\n",
    "            session.commit()\n",
    "\n",
    "            # print(f\"Query executed successfully. {rows_affected} rows affected.\")\n",
    "            return rows_affected\n",
    "    except Exception as e:\n",
    "        # Rollback changes if there's an error\n",
    "        session.rollback()\n",
    "        print(f\"Error executing query: {e}\")\n",
    "    finally:\n",
    "        # Close the session\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cf0378-4165-46bd-abc9-05c3a9fe18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def remove_mentions(tweet):\n",
    "    # Define regular expression pattern to match mentions\n",
    "    pattern = r'@\\w+'\n",
    "    \n",
    "    # Replace mentions with an empty string\n",
    "    cleaned_tweet = re.sub(pattern, '', tweet)\n",
    "    \n",
    "    return cleaned_tweet\n",
    "\n",
    "def stemming(comment):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    do = []\n",
    "    for w in comment:\n",
    "        dt = stemmer.stem(w)\n",
    "        do.append(dt)\n",
    "    d_clean = []\n",
    "    d_clean = \" \".join(do)\n",
    "    return d_clean\n",
    "    \n",
    "# function case folding\n",
    "def casefolding(comment):\n",
    "    comment = comment.lower()\n",
    "    comment = comment.strip(\" \")\n",
    "    comment = re.sub(r'[?|$|.|!_:\")(-+,]','',comment)\n",
    "    return comment\n",
    "\n",
    "def clean_up_tag(comment):\n",
    "    x_ret = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",comment).split())\n",
    "    return x_ret\n",
    "\n",
    "# Text Preprocessing, \n",
    "def text_preproc(strIn):\n",
    "    # case folding\n",
    "    strOut = strIn.lower()\n",
    "    \n",
    "    # remove numbers\n",
    "    strOut = re.sub(r\"\\d+\", \"\", strOut)\n",
    "    \n",
    "    # remote punctuation\n",
    "    strOut = strOut.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    \n",
    "    # remove whitspace\n",
    "    strOut = strOut.strip()\n",
    "    \n",
    "    # \n",
    "    strOut = re.sub('\\s+',' ',strOut)\n",
    "    return strOut\n",
    "\n",
    "# Check for return value NaN or None\n",
    "import numpy as np\n",
    "\n",
    "def is_nan_value(value):\n",
    "    \"\"\"\n",
    "    Check if the given value is NaN (Not a Number) or None.\n",
    "    \n",
    "    Parameters:\n",
    "        value: Any - The value to check.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the value is NaN or None, False otherwise.\n",
    "    \"\"\"\n",
    "    if isinstance(value, (int, float, np.number)):\n",
    "        return np.isnan(value)\n",
    "    elif value is None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438a292a-3e97-4161-bcaf-1887c838ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_by_df(source_ds):\n",
    "    from tqdm import tqdm\n",
    "    pd.options.mode.chained_assignment = None \n",
    "\n",
    "    # we calculate sentiment for 'title' and 'description' column\n",
    "\n",
    "    # remove first\n",
    "    source_ds['title'] = source_ds['title'].apply(clean_up_tag)\n",
    "    source_ds['description'] = source_ds['description'].apply(clean_up_tag)\n",
    "\n",
    "\n",
    "    # skip stemming\n",
    "    source_ds['stemmed'] = source_ds['title']\n",
    "    source_ds['stemmed'] = source_ds['stemmed'].apply(casefolding)\n",
    "    source_ds['stemmed'] = source_ds['stemmed'].apply(text_preproc)\n",
    "\n",
    "    sw = stopwords.words('indonesian')\n",
    "    # tokenized\n",
    "    source_ds['tokenized_tweet'] = source_ds.apply(lambda row: nltk.word_tokenize(row['stemmed']), axis=1)\n",
    "\n",
    "    # apply stopword removal\n",
    "    source_ds['tokenized_tweet'] = source_ds.apply(lambda row: {w for w in row['tokenized_tweet'] if not w in sw}, axis=1)\n",
    "\n",
    "    # Notes on return sentiment values\n",
    "    # 1 >> positif >> stay\n",
    "    # 2 >> negatif >> convert to -1\n",
    "    # 0 >> netral >> stay\n",
    "\n",
    "    # Create a new list and insert each element from the original list\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    list_text = source_ds['stemmed'].tolist()\n",
    "    new_list = []\n",
    "    for i in tqdm(range( len(list_text) )):\n",
    "        res = pipe(list_text[i])\n",
    "        #print(res)\n",
    "        new_list.append(res)\n",
    "\n",
    "    # Notes on return sentiment values\n",
    "    # 1 >> positif >> stay\n",
    "    # 2 >> negatif >> convert to -1\n",
    "    # 0 >> netral >> stay\n",
    "    # create a list of our conditions\n",
    "    for i in range(0, len(new_list)):\n",
    "        # print(new_list[i][0]['label'])\n",
    "        if new_list[i][0]['label'] == 'Positive':\n",
    "            new_list[i][0]['Value'] = 1\n",
    "        elif new_list[i][0]['label'] == 'Negative':\n",
    "            new_list[i][0]['Value'] = -1\n",
    "        elif new_list[i][0]['label'] == 'Neutral':\n",
    "            new_list[i][0]['Value'] = 0\n",
    "\n",
    "    for index, row in source_ds.iterrows():\n",
    "        source_ds.at[index,'Prediction'] = new_list[index][0]['label']\n",
    "\n",
    "    for index, row in source_ds.iterrows():\n",
    "        source_ds.at[index,'Prediction'] = new_list[index][0]['label']\n",
    "        source_ds.at[index,'Score'] = new_list[index][0]['score']\n",
    "        #source_ds.at[index,'Score'] = new_list[index][0]['Value']\n",
    "        \n",
    "    return source_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fa271b-38b8-4b07-bbf8-a47a457be5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to a file\n",
    "import logging\n",
    "logging.basicConfig(filename='error.log', level=logging.ERROR)\n",
    "\n",
    "def calculate_sentiment(row, col_description):\n",
    "    try:\n",
    "        # cleansing\n",
    "        strSource = row[col_description]\n",
    "\n",
    "        # cleansing\n",
    "        strSource = clean_up_tag(strSource)\n",
    "        strSource = casefolding(strSource)\n",
    "        strSource = text_preproc(strSource)\n",
    "        strSource = remove_mentions(strSource)\n",
    "\n",
    "        # tokenized\n",
    "        sToken = nltk.word_tokenize(strSource)\n",
    "\n",
    "        # remove stopwords\n",
    "        sw = stopwords.words('indonesian')\n",
    "\n",
    "        filtered_words = [word for word in sToken if word.lower() not in sw]\n",
    "        filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "        # Notes on return sentiment values\n",
    "        # 1 >> positif >> stay\n",
    "        # 2 >> negatif >> convert to -1\n",
    "        # 0 >> netral >> stay\n",
    "        result = pipe(strSource)\n",
    "\n",
    "        if result[0]['label'] == 'Negative':\n",
    "            sentimentClass = -1\n",
    "        elif result[0]['label'] == 'Positive':\n",
    "            sentimentClass = 1\n",
    "        else:\n",
    "            sentimentClass = 0\n",
    "\n",
    "        score = result[0]['score']\n",
    "        # handles NaN or non value\n",
    "        if (is_nan_value(score) or is_nan_value(sentimentClass)):\n",
    "            score = 0\n",
    "            sentimentClass = 0\n",
    "            \n",
    "        # put to result    \n",
    "        return pd.Series({'sentiment_category': sentimentClass, 'score': score})\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        # Log the exception to the error.log file\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        # Return default values or None for the columns\n",
    "        return pd.Series({'sentiment_category': None, 'score': None})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddf7fd2-8a76-4dd0-bae7-60ee6f765f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# calculate sentiment for youtube video\n",
    "#\n",
    "def record_youtube_sentiment(row):\n",
    "    ssql = \"\"\"\n",
    "    INSERT INTO public.youtube_result_sentiment \n",
    "    (id, sentiment_category, score, youtube_id) \n",
    "    VALUES(nextval('youtube_result_sentiment_id_seq'::regclass), %s, %s, '%s');\n",
    "    \"\"\" %(row['sentiment_category'],row['score'],row['id'])\n",
    "    #\n",
    "    # print(ssql)\n",
    "    execute_query(ssql)\n",
    "\n",
    "select_query = '''\n",
    "SELECT y.id, y.title\n",
    "FROM youtube y\n",
    "LEFT JOIN youtube_result_sentiment s ON y.id = s.youtube_id\n",
    "WHERE s.youtube_id IS NULL;\n",
    "'''\n",
    "\n",
    "source_ds3 = execute_query(select_query)\n",
    "id = ''\n",
    "\n",
    "if len(source_ds3) != 0:\n",
    "    for i in tqdm(range(len(source_ds3))):\n",
    "    # for i in range(len(source_ds3)):\n",
    "        row = source_ds3.iloc[i]\n",
    "        \n",
    "        id = row['id']\n",
    "        row = calculate_sentiment(row, 'title')    \n",
    "\n",
    "        # check value first\n",
    "        if (is_nan_value(row['sentiment_category']) or is_nan_value(row['score'])):\n",
    "            # store to rdbms\n",
    "            ssql = \"\"\"\n",
    "    INSERT INTO public.youtube_result_sentiment \n",
    "    (id, sentiment_category, score, youtube_id) \n",
    "    VALUES(nextval('youtube_result_sentiment_id_seq'::regclass), %s, %s, '%s');\n",
    "            \"\"\" %('0','0',id)\n",
    "        else:\n",
    "            # store to rdbms\n",
    "            ssql = \"\"\"\n",
    "INSERT INTO public.youtube_result_sentiment \n",
    "(id, sentiment_category, score, youtube_id) \n",
    "VALUES(nextval('youtube_result_sentiment_id_seq'::regclass), %s, %s, '%s');\n",
    "        \"\"\" %(row['sentiment_category'],row['score'],id)\n",
    "\n",
    "\n",
    "        # print(ssql)\n",
    "        execute_query(ssql)\n",
    "        \n",
    "        \n",
    "    #tqdm.pandas(desc=\"Processing\", total=len(source_ds3))\n",
    "    #source_ds3[['sentiment_category','score']] = source_ds3.progress_apply(calculate_sentiment, args=('title',), axis=1)\n",
    "    #source_ds3.apply(record_youtube_sentiment, axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2245df-c920-48cb-b72c-030423338466",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SA: 100%|██████████| 1000/1000 [19:30<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# calculate sentiment result for facebook post\n",
    "# \n",
    "\n",
    "def record_tiktok_sentiment(row):\n",
    "    # check for NaN\n",
    "    if (is_nan_value(row['sentiment_category']) or is_nan_value(row['score'])):\n",
    "        ssql = \"\"\"\n",
    "    INSERT INTO facebook_post_result_sentiment \n",
    "    (id, sentiment_category, score, facebook_id) \n",
    "    VALUES(nextval('facebook_post_result_sentiment_id_seq'::regclass), %s, %s, %s);\n",
    "    \"\"\" %('0','0',row['id'])\n",
    "    else:\n",
    "        ssql = \"\"\"\n",
    "    INSERT INTO facebook_post_result_sentiment \n",
    "    (id, sentiment_category, score, facebook_id) \n",
    "    VALUES(nextval('facebook_post_result_sentiment_id_seq'::regclass), %s, %s, %s);\n",
    "    \"\"\" %(row['sentiment_category'],row['score'],row['id'])\n",
    "    #\n",
    "    # print(ssql)\n",
    "    execute_query(ssql)\n",
    "\n",
    "select_query = \"\"\"\n",
    "SELECT \ta.id, a.description, a.name \n",
    "FROM \tfacebook_post a\n",
    "LEFT JOIN facebook_post_result_sentiment b ON a.id = b.facebook_id\n",
    "WHERE b.facebook_id IS NULL\n",
    "ORDER BY a.id desc limit 1000\n",
    "\"\"\"\n",
    "\n",
    "source_ds3 = execute_query(select_query)\n",
    "\n",
    "if len(source_ds3) != 0:\n",
    "    tqdm.pandas(desc=\"Calculating SA\", total = len(source_ds3))\n",
    "    source_ds3[['sentiment_category','score']] = source_ds3.progress_apply(calculate_sentiment, args=('description',), axis=1)\n",
    "    \n",
    "    #tqdm.pandas(desc=\"Recording SA\", total=len(source_ds3))\n",
    "    #source_ds3.progress_apply(record_tiktok_sentiment, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6194e71-aff4-44cb-85c6-8ee225d3ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ds3.to_pickle('source_ds3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
