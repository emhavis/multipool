{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370fc93b-6a63-4763-b344-3864c97bfb43",
   "metadata": {},
   "source": [
    "# Hashtag Counter\n",
    "For each dataset, each dataset is stored in db-id, below are the related table\n",
    "\n",
    "ret_available_db\n",
    "ret_tweet\n",
    "\n",
    "result stored in hashtag_counter with table structure of\n",
    "id, int -> primary key\n",
    "db_id, int -> foreign key to ret_available_db.db_id\n",
    "tweet_id, int -> foreign to ret_tweet.id\n",
    "hashtag_content, text -> the hashtag\n",
    "hashtag_counter, int -> how many times hashtag is encountered\n",
    "process_time, timestamp -> when the process is done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915e0ef-8d24-4a12-b4ce-57f126374450",
   "metadata": {},
   "source": [
    "## First Step\n",
    "query from database, that is not available in table hashtag_counter, take the last one first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be70d43-47cc-419c-bc80-de24490963c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_connector as dc\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "sql = \"\"\"\n",
    "select db_id from ret_available_db a  \n",
    "where a.db_id not in (select db_id from hashtag_counter union select db_id from hashtag_processed) \n",
    "and count > 0\n",
    "order by since desc \n",
    "limit 1\n",
    "\"\"\"\n",
    "\n",
    "df_db_id = dc.execute_query_psql(sql)\n",
    "const_dbid = df_db_id.iloc[0]['db_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2803fc68-a611-4eab-ad5b-a73799be4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87381\n"
     ]
    }
   ],
   "source": [
    "print(const_dbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff3f654-34de-4f31-8a74-604eec7f74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select  *\n",
    "from \tret_tweet a \n",
    "where \ta.db_id = %s\n",
    "\"\"\"\n",
    "# sql = sql % \"87546\"\n",
    "sql = sql % const_dbid\n",
    "df_source = dc.execute_query_psql(sql)\n",
    "\n",
    "#\n",
    "# handling zero rows dataset\n",
    "if len(df_source) == 0:\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO public.hashtag_processed\n",
    "        (db_id, process_time)\n",
    "        VALUES( %s, NOW());\"\"\"\n",
    "    sql = sql % (const_dbid)\n",
    "    print(\"recording db id %s as not existen\" % const_dbid)\n",
    "    dc.execute_query_psql(sql)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62638cfd-3967-45ee-80e6-051e2471d1dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def expand_hashtag(text):\n",
    "    hashtags = []\n",
    "    # print(text)\n",
    "    for match in re.findall(r'#(\\w+)', text):\n",
    "        # print(match)\n",
    "        hashtags.append(match)\n",
    "    return hashtags\n",
    "\n",
    "# define output column\n",
    "column_names = ['db_id','hashtag','tweet_id']\n",
    "\n",
    "# Create a blank DataFrame with predefined columns\n",
    "df_hashtag = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for index in range(len(df_source)):\n",
    "    strTweetString = str(df_source['tweet'].iloc[index])\n",
    "    # check if string is empty\n",
    "    if strTweetString.strip() != \"\":\n",
    "        list_res = expand_hashtag(strTweetString)\n",
    "        # check if no hashtag found\n",
    "        if len(list_res) > 0:\n",
    "            # print(list_res)    \n",
    "            for value in list_res:\n",
    "                new_row = { 'db_id' : const_dbid,\n",
    "                            'hashtag' : value,\n",
    "                            'tweet_id' : df_source['id'].iloc[index] }\n",
    "                # print(new_row)\n",
    "                df_hashtag.loc[len(df_hashtag)+1] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef1467-3814-4b7c-be2d-a8c6f5609162",
   "metadata": {},
   "source": [
    "## Record the result\n",
    "into table hashtags_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22eae0-469f-4893-a92b-55ea9664ac00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_hashtag)):\n",
    "    hashtag = df_hashtag.iloc[i]['hashtag']\n",
    "    # count = df_hashtag.iloc[i]['Count']\n",
    "    tweet_id = df_hashtag.iloc[i]['tweet_id']\n",
    "\n",
    "    dc.execute_query_psql(\n",
    "        \"\"\"\n",
    "        INSERT INTO public.hashtag_counter (db_id, hashtag_content, tweet_id, process_time)\n",
    "        VALUES (%s, '%s', %s, NOW())\n",
    "        \"\"\" % \n",
    "        (const_dbid, hashtag, tweet_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f34daa13-0285-44cc-805e-3920b702a6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d092a6-d6e9-4536-a22a-9060c2a8530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait 10 seconds before finished\n",
    "import time\n",
    "time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
