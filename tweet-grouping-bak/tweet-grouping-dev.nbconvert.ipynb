{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liked-washington",
   "metadata": {},
   "source": [
    "# Hashtag Grouping on Twitter\n",
    "\n",
    "Input: \n",
    "    Hastag scrap result from cekmedsos_database.vw_ttidata\n",
    "\n",
    "Output: \n",
    "    Mapping tables to group each hashtag entry with similarity\n",
    "    \n",
    "\n",
    "What we need to do....\n",
    "1. Load the table entry from mySQL into python\n",
    "2. Read the entry\n",
    "\n",
    "Pre-requisite\n",
    "pip install wheel\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-hayes",
   "metadata": {},
   "source": [
    "### 1. Create Connection to mySQL\n",
    "\n",
    "ref to this page:\n",
    "    [How to Use Python with mySQL in Jupyter](https://medium.com/@tattwei46/how-to-use-python-with-mysql-79304bee8753)\n",
    "    \n",
    "first, we need to install mysql connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-ticket",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:26.655351Z",
     "iopub.status.busy": "2021-06-27T16:10:26.649595Z",
     "iopub.status.idle": "2021-06-27T16:10:27.373540Z",
     "shell.execute_reply": "2021-06-27T16:10:27.374730Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-palestinian",
   "metadata": {},
   "source": [
    "### Input as proces started\n",
    "Record header and parameter information\n",
    "\n",
    " * Kesepakatan status di kolom screen_analisis_ai.status\n",
    " * 1 --> baru diinput\n",
    " * 2 --> lagi dikerjakan\n",
    " * 3 --> proses berhasil\n",
    " * 4 --> proses gagal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fresh-video",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:27.394577Z",
     "iopub.status.busy": "2021-06-27T16:10:27.392820Z",
     "iopub.status.idle": "2021-06-27T16:10:27.415402Z",
     "shell.execute_reply": "2021-06-27T16:10:27.416583Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#indonesiadaruratpinjol\n",
      "0.85\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get available jobs from database server, first come first serve\n",
    "sql = \"select id, hastag, `parameter` from screen_analisis_ai where id = 135\"\n",
    "# sql = \"select id, hastag, `parameter` \\\n",
    "# from screen_analisis_ai \\\n",
    "# where active = 1 \\\n",
    "# and status = 1 \\\n",
    "# and jenis_analisa = 1 \\\n",
    "# order by created asc, id asc limit 1\"\n",
    "\n",
    "row_count = cursor.execute(sql)\n",
    "\n",
    "if(row_count == 0):\n",
    "    # get out, nothing to do\n",
    "    print('Zero jobs, quitting now')\n",
    "    quit()\n",
    "\n",
    "result = cursor.fetchall()\n",
    "database_keyword_id = result[0]['hastag']\n",
    "similarity_treshold = result[0]['parameter']\n",
    "i_process_id = result[0]['id']\n",
    "screen_name = ''\n",
    "\n",
    "print(database_keyword_id)\n",
    "print(similarity_treshold)\n",
    "print(i_process_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-microwave",
   "metadata": {},
   "source": [
    "### Marking this process as running\n",
    "so that another process will not take this one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "processed-latino",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:27.429953Z",
     "iopub.status.busy": "2021-06-27T16:10:27.428345Z",
     "iopub.status.idle": "2021-06-27T16:10:27.447493Z",
     "shell.execute_reply": "2021-06-27T16:10:27.448713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Prepare SQL Statement\n",
    "print(i_process_id)\n",
    "sql = \"update screen_analisis_ai set status = 2, last_status_update = now(), start_process = now() where id = %s\"\n",
    "\n",
    "# execute\n",
    "cursor.execute(sql, i_process_id)\n",
    "\n",
    "# commit record\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-louisiana",
   "metadata": {},
   "source": [
    "### Runnning Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collective-validity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:27.465349Z",
     "iopub.status.busy": "2021-06-27T16:10:27.463822Z",
     "iopub.status.idle": "2021-06-27T16:10:27.488335Z",
     "shell.execute_reply": "2021-06-27T16:10:27.489524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#\n",
    "# Create Header Record\n",
    "sql = \"insert into ret_analysis_header (job_id, datetime_start, user_id) values (%s, %s, %s)\"\n",
    "# Execute the query\n",
    "print(i_process_id)\n",
    "cursor.execute(sql, (str(i_process_id), datetime.now(), 1 ))\n",
    "\n",
    "#\n",
    "# Create Parameter Record\n",
    "sql = \"insert into ret_analysis_parameter (job_id, param_id, param_name, param_value) values (%s, %s, %s, %s)\"\n",
    "# Execute the query\n",
    "cursor.execute(sql, (i_process_id, 1, 'Similarity Treshold', similarity_treshold))\n",
    "cursor.execute(sql, (i_process_id, 1, 'DB_ID', database_keyword_id))\n",
    "\n",
    "# Commit Record\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-lighting",
   "metadata": {},
   "source": [
    "#### Starting process, \n",
    "Run query against RDBMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weekly-jonathan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:27.503539Z",
     "iopub.status.busy": "2021-06-27T16:10:27.501832Z",
     "iopub.status.idle": "2021-06-27T16:10:27.681518Z",
     "shell.execute_reply": "2021-06-27T16:10:27.682822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select id, tweet, tweet_date_time from vw_ret_tweet_clean where keyword = \"#indonesiadaruratpinjol\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405743646347993095</td>\n",
       "      <td>SQUAD...! GO ✊ #IndonesiaDaruratPinjol Tagar P...</td>\n",
       "      <td>2021-06-18 11:26:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1405744059658895360</td>\n",
       "      <td>@BossTemlen UP ????????????  #IndonesiaDarurat...</td>\n",
       "      <td>2021-06-18 11:27:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1405744059667271685</td>\n",
       "      <td>Silakan barisan emak2 temlen .............naik...</td>\n",
       "      <td>2021-06-18 11:27:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1405744165707665408</td>\n",
       "      <td>@BossTemlen Go✊✊✊✊✊ #IndonesiaDaruratPinjol #I...</td>\n",
       "      <td>2021-06-18 11:28:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1405744283743707143</td>\n",
       "      <td>Setelah jumatan kita naikan tagar ini  #Indone...</td>\n",
       "      <td>2021-06-18 11:28:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "0  1405743646347993095  SQUAD...! GO ✊ #IndonesiaDaruratPinjol Tagar P...   \n",
       "1  1405744059658895360  @BossTemlen UP ????????????  #IndonesiaDarurat...   \n",
       "2  1405744059667271685  Silakan barisan emak2 temlen .............naik...   \n",
       "3  1405744165707665408  @BossTemlen Go✊✊✊✊✊ #IndonesiaDaruratPinjol #I...   \n",
       "4  1405744283743707143  Setelah jumatan kita naikan tagar ini  #Indone...   \n",
       "\n",
       "      tweet_date_time  \n",
       "0 2021-06-18 11:26:17  \n",
       "1 2021-06-18 11:27:55  \n",
       "2 2021-06-18 11:27:55  \n",
       "3 2021-06-18 11:28:21  \n",
       "4 2021-06-18 11:28:49  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# s_query_string = 'select id, tweet, tweet_date_time from ret_tweet where '\n",
    "s_query_string = 'select id, tweet, tweet_date_time from vw_ret_tweet_clean where '\n",
    "\n",
    "if (screen_name != ''):\n",
    "    # print('use screen name')\n",
    "    s_query_string = s_query_string + 'screen_name = \"' + screen_name + '\" and db_id = \"' + str(database_keyword_id) + '\"'\n",
    "else:\n",
    "    # print('no use')\n",
    "    s_query_string = s_query_string + 'keyword = \"' + database_keyword_id.replace('\"','') + '\"'\n",
    "    \n",
    "print(s_query_string)\n",
    "df = pd.read_sql(s_query_string, con=connection)\n",
    "\n",
    "# Close Connection\n",
    "connection.close()\n",
    "\n",
    "# see result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-waste",
   "metadata": {},
   "source": [
    "### 2. Try to pre-process all the text\n",
    "\n",
    "target-> tokenizing into another dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chemical-bulgarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:27.690248Z",
     "iopub.status.busy": "2021-06-27T16:10:27.688637Z",
     "iopub.status.idle": "2021-06-27T16:10:28.664102Z",
     "shell.execute_reply": "2021-06-27T16:10:28.665409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405743646347993095</td>\n",
       "      <td>squad go ✊ indonesiadaruratpinjol tagar peduli...</td>\n",
       "      <td>2021-06-18 11:26:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1405744059658895360</td>\n",
       "      <td>bosstemlen up indonesiadaruratpinjol indonesia...</td>\n",
       "      <td>2021-06-18 11:27:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1405744059667271685</td>\n",
       "      <td>silakan barisan emak temlen naikan duluan taga...</td>\n",
       "      <td>2021-06-18 11:27:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1405744165707665408</td>\n",
       "      <td>bosstemlen go✊✊✊✊✊ indonesiadaruratpinjol indo...</td>\n",
       "      <td>2021-06-18 11:28:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1405744283743707143</td>\n",
       "      <td>setelah jumatan kita naikan tagar ini indonesi...</td>\n",
       "      <td>2021-06-18 11:28:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "0  1405743646347993095  squad go ✊ indonesiadaruratpinjol tagar peduli...   \n",
       "1  1405744059658895360  bosstemlen up indonesiadaruratpinjol indonesia...   \n",
       "2  1405744059667271685  silakan barisan emak temlen naikan duluan taga...   \n",
       "3  1405744165707665408  bosstemlen go✊✊✊✊✊ indonesiadaruratpinjol indo...   \n",
       "4  1405744283743707143  setelah jumatan kita naikan tagar ini indonesi...   \n",
       "\n",
       "      tweet_date_time  \n",
       "0 2021-06-18 11:26:17  \n",
       "1 2021-06-18 11:27:55  \n",
       "2 2021-06-18 11:27:55  \n",
       "3 2021-06-18 11:28:21  \n",
       "4 2021-06-18 11:28:49  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Text Preprocessing, \n",
    "def text_preproc(strIn):\n",
    "    # case folding\n",
    "    strOut = strIn.lower()\n",
    "    # remove numbers\n",
    "    strOut = re.sub(r\"\\d+\", \"\", strOut)\n",
    "    # remote punctuation\n",
    "    strOut = strOut.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    # remove whitspace\n",
    "    strOut = strOut.strip()\n",
    "    # \n",
    "    strOut = re.sub('\\s+',' ',strOut)\n",
    "    \n",
    "    return strOut\n",
    "# end Text Preprocessing\n",
    "\n",
    "\n",
    "# Apply to data frame\n",
    "df['tweet'] = df['tweet'].apply(text_preproc)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-power",
   "metadata": {},
   "source": [
    "### Finish preprocessing, Tokenized\n",
    "Next step, is to output to new column for tokenized sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "classical-position",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:28.672865Z",
     "iopub.status.busy": "2021-06-27T16:10:28.671192Z",
     "iopub.status.idle": "2021-06-27T16:10:30.099215Z",
     "shell.execute_reply": "2021-06-27T16:10:30.100544Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Load stopwords\n",
    "sw = stopwords.words('indonesian')\n",
    "\n",
    "# apply tokenize\n",
    "df['tokenized_tweet'] = df.apply(lambda row: nltk.word_tokenize(row['tweet']), axis=1)\n",
    "# apply stopword removal\n",
    "df['sw'] = df.apply(lambda row: {w for w in row['tokenized_tweet'] if not w in sw}, axis=1)\n",
    "\n",
    "# print((df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-commerce",
   "metadata": {},
   "source": [
    "### Define function to calculate similarity\n",
    "Function return similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "close-sessions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:30.108080Z",
     "iopub.status.busy": "2021-06-27T16:10:30.106460Z",
     "iopub.status.idle": "2021-06-27T16:10:30.131469Z",
     "shell.execute_reply": "2021-06-27T16:10:30.132773Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(X_set, Y_set):\n",
    "# Program to measure the similarity between  \n",
    "# two sentences using cosine similarity. \n",
    "\n",
    "    l1 =[];l2 =[]\n",
    "\n",
    "    # form a set containing keywords of both strings  \n",
    "    rvector = X_set.union(Y_set)  \n",
    "    for w in rvector: \n",
    "        if w in X_set: l1.append(1) # create a vector\n",
    "        else: l1.append(0) \n",
    "        if w in Y_set: l2.append(1) \n",
    "        else: l2.append(0) \n",
    "    c = 0\n",
    "\n",
    "    # cosine formula  \n",
    "    for i in range(len(rvector)): \n",
    "            c+= l1[i]*l2[i] \n",
    "    cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
    "    \n",
    "    return cosine\n",
    "\n",
    "def largest_in_col(arr,nCol):\n",
    "    # \n",
    "    # Find largest value of col nCol on 2D arr\n",
    "    #\n",
    "    \n",
    "    # init value\n",
    "    max_val = arr[0][nCol]\n",
    "    # also, remember index\n",
    "    row_index = 0\n",
    "    \n",
    "    for x in range(0, len(arr)):\n",
    "        if arr[x][nCol] > max_val:\n",
    "            max_val = arr[x][nCol]\n",
    "            row_index = x\n",
    "        \n",
    "    return max_val,row_index\n",
    "\n",
    "def smallest_in_col(arr,nCol):\n",
    "    # \n",
    "    # Find smallest value of col nCol on 2D arr\n",
    "    #\n",
    "    \n",
    "    # init value\n",
    "    min_val = arr[0][nCol]\n",
    "    # also, remember index\n",
    "    row_index = 0\n",
    "    \n",
    "    for x in range(0, len(arr)):\n",
    "        if arr[x][nCol] < min_val:\n",
    "            min_val = arr[x][nCol]\n",
    "            row_index = x\n",
    "        \n",
    "    return min_val,row_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-appearance",
   "metadata": {},
   "source": [
    "### Try to using function\n",
    "using some of array cells, create n matrices\n",
    "\n",
    "1. take one tweet, compare to all data set\n",
    "2. flag 1 if similar\n",
    "3. take next tweet, if similar from prev tweet, skip\n",
    "4. if not similar, add counter, then proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unavailable-clearing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:10:30.140426Z",
     "iopub.status.busy": "2021-06-27T16:10:30.138746Z",
     "iopub.status.idle": "2021-06-27T16:13:00.157608Z",
     "shell.execute_reply": "2021-06-27T16:13:00.159670Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1959210/1959210.0 [02:29<00:00, 13064.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. 16.  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import array as arr\n",
    "# import multitasking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set to max CPU Cores\n",
    "# multitasking.set_max_threads(multitasking.config[\"CPU_CORES\"] * 5)\n",
    "\n",
    "st = similarity_treshold\n",
    "cluster_no = 1\n",
    "s_score = 0\n",
    "s_score_current = 0\n",
    "i_current_cluster = 0\n",
    "\n",
    "#create zero element array\n",
    "#col 0 => index base tweet\n",
    "#col 1 => cluster number\n",
    "#col 2 => similarity score\n",
    "base_tweet = []\n",
    "\n",
    "#proceed to compare to all tweet\n",
    "cosine_matrix = np.zeros(( len(df), len(df) ))\n",
    "\n",
    "# flag the mt\n",
    "with tqdm(total=( (len(df)*len(df)/2))-(len(df)/2))  as pbar:\n",
    "    for j in range(0, len(df)):\n",
    "        tweet_to_compare = df['sw'][j]\n",
    "\n",
    "        #check, is this second tweet?\n",
    "        if(j == 0):\n",
    "            #first tweet, add as cluster no #1\n",
    "            base_tweet.append([j,1,1.0])\n",
    "            i_current_cluster = base_tweet[0][1]\n",
    "\n",
    "        elif(j == 1):\n",
    "            #compare to prev tweet\n",
    "            s_score = calculate_similarity(tweet_to_compare, df['sw'][ base_tweet[0][0] ])\n",
    "\n",
    "            if(s_score < st):\n",
    "                #not similar\n",
    "                base_tweet.append([j,2,1])\n",
    "                i_current_cluster = base_tweet[j][1]\n",
    "\n",
    "        else:\n",
    "            #other else tweet\n",
    "            for x in range(0,len(base_tweet)):\n",
    "                #compare every element\n",
    "                s_score = calculate_similarity(tweet_to_compare, df['sw'][ base_tweet[x][0] ])\n",
    "                base_tweet[x][2] = s_score\n",
    "\n",
    "            if(largest_in_col(base_tweet,2)[0] < st):\n",
    "                #no similar, add as one new cluster\n",
    "                i_current_cluster = i_current_cluster + 1\n",
    "                base_tweet.append([j,i_current_cluster,largest_in_col(base_tweet,2)[0]])\n",
    "            else:\n",
    "                #determine cluster# from biggest similarity\n",
    "                i_current_cluster = base_tweet[(largest_in_col(base_tweet,2)[1])][1]\n",
    "\n",
    "        #proceed to compare to all tweet\n",
    "        for i in range(0,len(df)):\n",
    "            # update progress\n",
    "            if (j<i):\n",
    "                pbar.update(1)\n",
    "                s_score = calculate_similarity(tweet_to_compare, df['sw'][i])\n",
    "                if (s_score >= st):\n",
    "                    cosine_matrix[i,j] = i_current_cluster\n",
    "\n",
    "        \n",
    "pbar.close()\n",
    "print(cosine_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-transparency",
   "metadata": {},
   "source": [
    "### Writing result to file\n",
    "Using NPZ format for efficiency, and try to load them after save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "valid-mobile",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:13:00.175602Z",
     "iopub.status.busy": "2021-06-27T16:13:00.173095Z",
     "iopub.status.idle": "2021-06-27T16:13:00.879436Z",
     "shell.execute_reply": "2021-06-27T16:13:00.880630Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n",
      "Save data complete .... \n"
     ]
    }
   ],
   "source": [
    "# save numpy array as npz file\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from numpy import savetxt\n",
    "\n",
    "# save to npy file\n",
    "# savez_compressed('./output/df_380.npz',df)\n",
    "# savez_compressed('./output/data_380.npz', cosine_matrix)\n",
    "# savez_compressed('./output/data_380_base.npz', base_tweet)\n",
    "\n",
    "# savetxt('cosine-matrix.csv', cosine_matrix, delimiter = ',')\n",
    "\n",
    "print(len(cosine_matrix))\n",
    "print('Save data complete .... ')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# sns.heatmap(cosine_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-tennessee",
   "metadata": {},
   "source": [
    "### How to save to rdbms?\n",
    "save the header data, meta data of the process\n",
    "[ret_analysis_header]\n",
    "- JobID\n",
    "- user initiated\n",
    "- Time Started\n",
    "- Time End\n",
    "\n",
    "Process Parameter\n",
    "[ret_analysis_parameter]\n",
    "- JobID\n",
    "- Param Name\n",
    "- Param Value\n",
    "    - ST Value\n",
    "    - DB ID\n",
    "    - Screen Name\n",
    "    - How Many Tweet analyzed\n",
    "\n",
    "save detail cluster information\n",
    "[ret_base_tweet]\n",
    "- JobID\n",
    "- Tweet Base# --> tweet ID\n",
    "- Cluster#\n",
    "\n",
    "save detail calculation result, structure\n",
    "[ret_cluster_result]\n",
    "- JobID\n",
    "- TweetID\n",
    "- Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tribal-intent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:13:00.896794Z",
     "iopub.status.busy": "2021-06-27T16:13:00.895192Z",
     "iopub.status.idle": "2021-06-27T16:13:04.170246Z",
     "shell.execute_reply": "2021-06-27T16:13:04.172319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished inserting base tweet record\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#\n",
    "# Create Base Tweet Record\n",
    "sql = \"insert into ret_base_tweet (job_id, tweet_id, cluster_id) values (%s, %s, %s)\"\n",
    "\n",
    "## inserting base tweet\n",
    "for i in range(0,len(base_tweet)):\n",
    "    # Execute the query\n",
    "    cursor.execute(sql, (i_process_id, df['id'][i], base_tweet[i][1]))\n",
    "    \n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print('finished inserting base tweet record')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-kennedy",
   "metadata": {},
   "source": [
    "### Record cluster result\n",
    "into table ret_cluster_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "painted-nylon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:13:04.206522Z",
     "iopub.status.busy": "2021-06-27T16:13:04.203684Z",
     "iopub.status.idle": "2021-06-27T16:13:15.768595Z",
     "shell.execute_reply": "2021-06-27T16:13:15.770426Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished inserting cluster data\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#\n",
    "# Create Tweet Cluster Record\n",
    "sql = \"insert into ret_cluster_result (job_id, tweet_id, cluster_no) values (%s, %s, %s)\"\n",
    "\n",
    "# initiate cluster number\n",
    "i_cluster_no_save = 0\n",
    "i_cluster_min = 0\n",
    "temp_val = 0\n",
    "                 \n",
    "## inserting tweet cluster\n",
    "for i in range(0, len(cosine_matrix)):\n",
    "# for i in range(0, 50):\n",
    "    # find value in this particular col\n",
    "    i_cluster_no_save = largest_in_col(cosine_matrix,i)\n",
    "    i_cluster_min = smallest_in_col(cosine_matrix,i)\n",
    "    \n",
    "    # print(i)    \n",
    "    # print('max cluster no', i_cluster_no_save)\n",
    "    # print('min cluster no',i_cluster_min)\n",
    "    # print(i_process_id, df['id'][i_cluster_no_save[1]], int(i_cluster_no_save[0]))\n",
    "    \n",
    "    # Execute the query\n",
    "    cursor.execute(sql, (i_process_id, df['id'][i_cluster_no_save[1]], int(i_cluster_no_save[0])))\n",
    "    \n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print('finished inserting cluster data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-foundation",
   "metadata": {},
   "source": [
    "### Record finish time\n",
    "update table ret_analysis_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mighty-florence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:13:15.786677Z",
     "iopub.status.busy": "2021-06-27T16:13:15.785197Z",
     "iopub.status.idle": "2021-06-27T16:13:15.815887Z",
     "shell.execute_reply": "2021-06-27T16:13:15.817072Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "job finished\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#\n",
    "# Create Parameter Record\n",
    "sql = \"insert into ret_analysis_parameter (job_id, param_id, param_name, param_value) values (%s, %s, %s, %s)\"\n",
    "# Execute the query\n",
    "cursor.execute(sql, (i_process_id, 1, '#Tweet Processed',len(df)))\n",
    "\n",
    "#\n",
    "# Create Tweet Cluster Record\n",
    "sql = \"update ret_analysis_header set datetime_finish = %s where job_id = %s\"\n",
    "# Executing query\n",
    "cursor.execute(sql, (datetime.now(),i_process_id) )\n",
    "\n",
    "print(i_process_id)\n",
    "\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print('job finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-brown",
   "metadata": {},
   "source": [
    "### Marking as finished the job\n",
    "on this particular i_process_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "august-interaction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:13:15.830545Z",
     "iopub.status.busy": "2021-06-27T16:13:15.828987Z",
     "iopub.status.idle": "2021-06-27T16:13:15.849780Z",
     "shell.execute_reply": "2021-06-27T16:13:15.848602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "sql = \"update screen_analisis_ai set status = 3, end_process = now(), duration = TIMESTAMPDIFF(second,start_process, end_process) where id = %s\"\n",
    "# Executing query\n",
    "cursor.execute(sql,i_process_id)\n",
    "\n",
    "# commit changes\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-tooth",
   "metadata": {},
   "source": [
    "### Next thing todo list ...\n",
    "1. Create data structure to record below things\n",
    "    Job Header\n",
    "    - JobID\n",
    "    - Similarity Treshold\n",
    "    - Dataset Parameter\n",
    "        - By User\n",
    "        - By Keyword\n",
    "    - Running time start\n",
    "    - Running time end\n",
    "    \n",
    "    Dataset Result\n",
    "        - base_tweet\n",
    "        - cosine_matrix\n",
    "        \n",
    "2. Push the result data into RDBMS Server, in this case is mySQL\n",
    "    - upload csv file to mySQL\n",
    "    - import to database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-helmet",
   "metadata": {},
   "source": [
    "## Copy these table structure into paj-dev\n",
    "1. ret_analysis_parameter\n",
    "2. ret_base_tweet\n",
    "3. ret_cluster_result\n",
    "4. vw_ret_tweet_clean\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "saving-technique",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T16:13:15.858700Z",
     "iopub.status.busy": "2021-06-27T16:13:15.857269Z",
     "iopub.status.idle": "2021-06-27T16:14:15.933464Z",
     "shell.execute_reply": "2021-06-27T16:14:15.930263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wait 60 sec before release\n",
    "time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
