{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wound-airfare",
   "metadata": {},
   "source": [
    "## Compute Similarities between images\n",
    "Using Structural Similarity Index\n",
    "\n",
    "Importing all necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "immediate-estonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done importing modules\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import urllib\n",
    "\n",
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import image_similarity_measures\n",
    "import urllib.request as rq\n",
    "\n",
    "# create matrix\n",
    "import numpy as np\n",
    "import array as arr\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "from image_tools.sizes import resize_and_crop\n",
    "from image_similarity_measures.quality_metrics import ssim, sam, sre\n",
    "\n",
    "\n",
    "print('done importing modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-defeat",
   "metadata": {},
   "source": [
    "### Querying Data from server\n",
    "based on given job id\n",
    "\n",
    "### Input as proces started\n",
    "Record header and parameter information\n",
    "\n",
    " * Kesepakatan status di kolom screen_analisis_ai.status\n",
    " * 1 --> baru diinput\n",
    " * 2 --> lagi dikerjakan\n",
    " * 3 --> proses berhasil\n",
    " * 4 --> proses gagal\n",
    " *\n",
    " \n",
    " * Kesepakatan jenis analisa AI\n",
    " * 1 --> Analisa Cluster\n",
    " * 2 --> Analisa image clustering\n",
    " * 3 --> Analisa sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intellectual-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select id, hastag, `parameter` from screen_analisis_ai where active = 1 and status = 1 and jenis_analisa = 2 order by created asc, id asc limit 1\n",
      "2380\n",
      "0.88\n",
      "723\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get available jobs from database server, first come first serve\n",
    "sql = \"select id, hastag, `parameter` \\\n",
    "from screen_analisis_ai \\\n",
    "where active = 1 \\\n",
    "and status = 1 \\\n",
    "and jenis_analisa = 2 \\\n",
    "order by created asc, id asc limit 1\"\n",
    "\n",
    "print(sql)\n",
    "\n",
    "row_count = cursor.execute(sql)\n",
    "\n",
    "if(row_count == 0):\n",
    "    # get out, nothing to do\n",
    "    print('Zero jobs, quitting now')\n",
    "    quit()\n",
    "\n",
    "result = cursor.fetchall()\n",
    "database_keyword_id = result[0]['hastag']\n",
    "similarity_treshold = result[0]['parameter']\n",
    "i_process_id = result[0]['id']\n",
    "screen_name = ''\n",
    "\n",
    "print(database_keyword_id)\n",
    "print(similarity_treshold)\n",
    "print(i_process_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-theme",
   "metadata": {},
   "source": [
    "### Mark Process as Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "trying-celebration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Prepare SQL Statement\n",
    "print(i_process_id)\n",
    "sql = \"update screen_analisis_ai set status = 2, last_status_update = now(), start_process = now() where id = %s\"\n",
    "# execute\n",
    "cursor.execute(sql, i_process_id)\n",
    "\n",
    "#\n",
    "# Create Header Record\n",
    "sql = \"insert into ret_analysis_header (job_id, datetime_start, user_id) values (%s, %s, %s)\"\n",
    "# Execute the query\n",
    "cursor.execute(sql, (str(i_process_id), datetime.now(), 1 ))\n",
    "\n",
    "#\n",
    "# Create Parameter Record\n",
    "sql = \"insert into ret_analysis_parameter (job_id, param_id, param_name, param_value) values (%s, %s, %s, %s)\"\n",
    "# Execute the query\n",
    "cursor.execute(sql, (i_process_id, 1, 'Similarity Treshold', similarity_treshold))\n",
    "cursor.execute(sql, (i_process_id, 1, 'DB_ID', database_keyword_id))\n",
    "\n",
    "# commit record\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-washington",
   "metadata": {},
   "source": [
    "### Query data from RDBMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "patient-shipping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select a.id,a.db_id,c.tweet_id,c.filename from ret_available_db a inner join ret_tweet b on a.db_id = b.db_id inner join media_files c on a.db_id = c.db_id and b.id = c.tweet_id where \ta.db_id = 2380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>db_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2138</td>\n",
       "      <td>2380</td>\n",
       "      <td>1395529845384257537</td>\n",
       "      <td>60b505caac466.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2138</td>\n",
       "      <td>2380</td>\n",
       "      <td>1395530655920922626</td>\n",
       "      <td>60b505cb4c365.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2138</td>\n",
       "      <td>2380</td>\n",
       "      <td>1395530992727646212</td>\n",
       "      <td>60b505cb93c65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2138</td>\n",
       "      <td>2380</td>\n",
       "      <td>1395532469667987456</td>\n",
       "      <td>60b505cbd4fab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2138</td>\n",
       "      <td>2380</td>\n",
       "      <td>1395532534113394695</td>\n",
       "      <td>60b505cc93fef.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  db_id             tweet_id           filename\n",
       "0  2138   2380  1395529845384257537  60b505caac466.jpg\n",
       "1  2138   2380  1395530655920922626  60b505cb4c365.jpg\n",
       "2  2138   2380  1395530992727646212  60b505cb93c65.jpg\n",
       "3  2138   2380  1395532469667987456  60b505cbd4fab.jpg\n",
       "4  2138   2380  1395532534113394695  60b505cc93fef.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_db_id = database_keyword_id\n",
    "## similarity_treshold = 0.8\n",
    "\n",
    "#\n",
    "# Query to get tweet data, apply analitics to this dataset\n",
    "#\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "s_query_string = \"select a.id,\\\n",
    "a.db_id,\\\n",
    "c.tweet_id,\\\n",
    "c.filename \\\n",
    "from ret_available_db a \\\n",
    "inner join ret_tweet b \\\n",
    "on a.db_id = b.db_id \\\n",
    "inner join media_files c \\\n",
    "on a.db_id = c.db_id \\\n",
    "and b.id = c.tweet_id \\\n",
    "where \ta.db_id = \" + str(i_db_id)\n",
    "    \n",
    "print(s_query_string)\n",
    "df = pd.read_sql(s_query_string, con=connection)\n",
    "\n",
    "# Close Connection\n",
    "connection.close()\n",
    "\n",
    "# see result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-telling",
   "metadata": {},
   "source": [
    "### Defining Functions\n",
    "To compare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "promotional-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done implement function\n"
     ]
    }
   ],
   "source": [
    "# load image from url\n",
    "def urlToImage(url):\n",
    "    # download image,convert to a NumPy array,and read it into opencv\n",
    "    resp = rq.urlopen(url)\n",
    "    img = np.asarray(bytearray(resp.read()),dtype=\"uint8\")\n",
    "    img = cv2.imdecode(img,cv2.IMREAD_COLOR)\n",
    "\n",
    "    #return the image\n",
    "    return img\n",
    "\n",
    "def mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err\n",
    "\n",
    "def compare_images(imageA, imageB, title):\n",
    "\t# compute the mean squared error and structural similarity\n",
    "\t# index for the images\n",
    "\tm = mse(imageA, imageB)\n",
    "\ts = ssim(imageA, imageB)\n",
    "    \n",
    "\t# setup the figure\n",
    "\tfig = plt.figure(title)\n",
    "\tplt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "    \n",
    "\t# show first image\n",
    "\tax = fig.add_subplot(1, 2, 1)\n",
    "\tplt.imshow(imageA, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    "    \n",
    "\t# show the second image\n",
    "\tax = fig.add_subplot(1, 2, 2)\n",
    "\tplt.imshow(imageB, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    "\t# show the images\n",
    "\tplt.show()\n",
    "    \n",
    "def largest_in_col(arr,nCol):\n",
    "    # \n",
    "    # Find largest value of col nCol on 2D arr\n",
    "    #\n",
    "    \n",
    "    # init value\n",
    "    max_val = arr[0][nCol]\n",
    "    # also, remember index\n",
    "    row_index = 0\n",
    "    \n",
    "    for x in range(0, len(arr)):\n",
    "        if arr[x][nCol] > max_val:\n",
    "            max_val = arr[x][nCol]\n",
    "            row_index = x\n",
    "        \n",
    "    return max_val,row_index\n",
    "\n",
    "def largest_in_row(arr,nRow):\n",
    "    # \n",
    "    # Find largest value of row nRow on 2D arr\n",
    "    #\n",
    "    \n",
    "    # initial value\n",
    "    max_val = arr[nRow][0]\n",
    "    # also, remember index\n",
    "    col_index = 0\n",
    "    \n",
    "    for x in range(0, len(arr)):\n",
    "        if arr[nRow][x] > max_val:\n",
    "            max_val = arr[nRow][x]\n",
    "            col_index = x\n",
    "            \n",
    "    return max_val,col_index  \n",
    "\n",
    "    \n",
    "\n",
    "print('done implement function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "shared-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgUrl = \"https://cekmedsos.com/uploads/twimg/\" + df['filename'][1]\n",
    "# img_base = Image.open(requests.get(imgUrl, stream=True).raw)\n",
    "# wa, ha = img_base.size\n",
    "# print(wa,ha)\n",
    "\n",
    "# imgUrl = \"https://cekmedsos.com/uploads/twimg/\" + df['filename'][2]\n",
    "# img_compare = Image.open(requests.get(imgUrl, stream=True).raw)\n",
    "\n",
    "# fig = plt.figure('test')\n",
    "# ax = fig.add_subplot(1, 2, 1)\n",
    "# plt.imshow(img_base, cmap = plt.cm.gray)\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# size_check = check_image_size(img_base, img_compare)\n",
    "# print('size_check = ' + str(size_check))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img_base = cv2.cvtColor(np.float32(img_base), cv2.COLOR_BGR2GRAY)\n",
    "# img_compare = cv2.cvtColor(np.float32(img_compare), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# compare_images(img_base, img_compare, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-contribution",
   "metadata": {},
   "source": [
    "### Perform Image Compare\n",
    "By loading the images\n",
    "\n",
    "1. Compares itself\n",
    "2. Compare to Contrast Editing\n",
    "3. Compare to PS editing (Black box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interracial-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "satisfactory-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "def match_size(imgA, imgB):\n",
    "    tf = tempfile.NamedTemporaryFile(suffix='.jpg')\n",
    "    tf_ = tempfile.NamedTemporaryFile(suffix='.jpg')\n",
    "    \n",
    "    # which one have more pixels?\n",
    "    pxA = imgA.shape[0]*imgA.shape[1]\n",
    "    pxB = imgB.shape[0]*imgB.shape[1]\n",
    "    \n",
    "    # handle odd pixel size\n",
    "    #print('W/H= ' + str(imgA.shape[0]) + '/' + str(imgA.shape[1]))\n",
    "    #print('W/H= ' + str(imgB.shape[0]) + '/' + str(imgB.shape[1]))\n",
    "\n",
    "    if(pxA < pxB):\n",
    "        # print('resize imgB to match imgA')\n",
    "        # save temp file imgB\n",
    "        cv2.imwrite(tf.name,imgB)\n",
    "        imgRes = resize_and_crop(\n",
    "                        tf.name, \n",
    "                        (imgA.shape[1],imgA.shape[0]), #set width and height to match img1\n",
    "                        crop_origin=\"middle\"\n",
    "                        )\n",
    "        # save temp file imgA        \n",
    "        cv2.imwrite(tf_.name,imgA)\n",
    "        imgRes_ = resize_and_crop(\n",
    "                        tf_.name, \n",
    "                        (imgA.shape[1],imgA.shape[0]), #set width and height to match img1\n",
    "                        crop_origin=\"middle\"\n",
    "                        )        \n",
    "        \n",
    "        del tf\n",
    "        del tf_\n",
    "    else:\n",
    "        # print('resize imgA to match imgB')\n",
    "        # save temp file imgB\n",
    "        cv2.imwrite(tf.name,imgA)\n",
    "        imgRes = resize_and_crop(\n",
    "                        tf.name, \n",
    "                        (imgB.shape[1],imgB.shape[0]), #set width and height to match img1\n",
    "                        crop_origin=\"middle\"\n",
    "                        )\n",
    "        # save temp file imgB       \n",
    "        cv2.imwrite(tf_.name,imgB)\n",
    "        imgRes_ = resize_and_crop(\n",
    "                        tf_.name, \n",
    "                        (imgB.shape[1],imgB.shape[0]), #set width and height to match img1\n",
    "                        crop_origin=\"middle\"\n",
    "                        )             \n",
    "        del tf\n",
    "        del tf_\n",
    "        \n",
    "    # need to check for pixel difference between images\n",
    "    if imgRes.size[0] != imgRes_.size[0]:\n",
    "        # print('diff width')\n",
    "        # which one bigger?\n",
    "        if imgRes.size[0] > imgRes_.size[0]:\n",
    "            # crop to imgRes to match imgRes_\n",
    "            # print('cropping imgRes to match imgRes_')\n",
    "            imgRes = imgRes.crop((0,0,imgRes_.size[0], imgRes_.size[1]))\n",
    "        else:\n",
    "            # crop to imgRes_ to match imgRes\n",
    "            # print('cropping imgRes_ to match imgRes')\n",
    "            imgRes_ = imgRes_.crop((0,0,imgRes.size[0], imgRes.size[1]))           \n",
    "        \n",
    "    if imgRes.size[1] != imgRes_.size[1]:\n",
    "        # print('diff height')\n",
    "        # which one bigger?\n",
    "        if imgRes.size[1] > imgRes_.size[1]:\n",
    "            # crop to imgRes to match imgRes_\n",
    "            #print('cropping imgRes to match imgRes_')\n",
    "            imgRes = imgRes.crop((0,0,imgRes_.size[0], imgRes_.size[1]))\n",
    "        else:\n",
    "            # crop to imgRes_ to match imgRes\n",
    "            #print('cropping imgRes_ to match imgRes')\n",
    "            imgRes_ = imgRes_.crop((0,0,imgRes.size[0], imgRes.size[1]))            \n",
    "            \n",
    "        \n",
    "    return imgRes, imgRes_\n",
    "#\n",
    "# END Function\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latest-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgA = urlToImage(\"https://cekmedsos.com/uploads/twimg/60b5246c4827f.jpg\")\n",
    "# imgB = urlToImage(\"https://cekmedsos.com/uploads/twimg/60b5246b3c5ad.jpg\")\n",
    "\n",
    "# img_one, img_two = match_size(imgB, imgA)\n",
    "# img_one = cv2.cvtColor(np.float32(img_one), cv2.COLOR_BGR2GRAY)\n",
    "# img_two = cv2.cvtColor(np.float32(img_two), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# #print(str(img_one.shape[0]) + '/' + str(img_one.shape[1]))\n",
    "# #print(str(img_two.shape[0]) + '/' + str(img_two.shape[1]))\n",
    "\n",
    "# #print(img_two.size)\n",
    "\n",
    "# # plt.imshow(imgA)\n",
    "# #.imshow(imgB)\n",
    "\n",
    "\n",
    "# s = ssim(img_one, img_two)\n",
    "\n",
    "# # image-similarity-measures --org_img_path test-3.jpg --pred_img_path test-4.jpg --metric=all\n",
    "# print('Similarity Index')\n",
    "# print(s)\n",
    "\n",
    "# print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-caribbean",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 2042/3081.0 [14:21<09:44,  1.78it/s]"
     ]
    }
   ],
   "source": [
    "st = similarity_treshold\n",
    "cluster_no = 1\n",
    "s_score = 0\n",
    "s_score_current = 0\n",
    "i_current_cluster = 0\n",
    "\n",
    "def check_image_size(imageA, imageB):\n",
    "    wa = imageA.shape[0]\n",
    "    ha = imageA.shape[1]\n",
    "    \n",
    "    wb = imageB.shape[0]\n",
    "    hb = imageB.shape[1]\n",
    "    \n",
    "    if(wa == wb and ha == hb):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#create zero element array\n",
    "#col 0 => index base tweet\n",
    "#col 1 => cluster number\n",
    "#col 2 => similarity score\n",
    "base_tweet = []\n",
    "\n",
    "ssim_matrix = np.zeros(( len(df), len(df) ), dtype=np.dtype('f4'))\n",
    "\n",
    "with tqdm(total=( (len(df)*len(df)/2))-(len(df)/2))  as pbar:\n",
    "    ## Kolom\n",
    "    for j in range(0, len(df)):\n",
    "        # get url\n",
    "        imgUrl = \"https://cekmedsos.com/uploads/twimg/\" + df['filename'][j]\n",
    "        img_base = urlToImage(imgUrl)\n",
    "        \n",
    "        ## Baris\n",
    "        for i in range(0,len(df)):\n",
    "            if (j<i):\n",
    "                # get url\n",
    "                imgUrl = \"https://cekmedsos.com/uploads/twimg/\" + df['filename'][i]\n",
    "                # print(imgUrl)\n",
    "                img_compare = urlToImage(imgUrl)\n",
    "                \n",
    "                # do image check size\n",
    "                if(check_image_size(img_base, img_compare)):\n",
    "                    # do check images ssim\n",
    "                    \n",
    "                    img_compare_one = cv2.cvtColor(np.float32(img_base), cv2.COLOR_BGR2GRAY)\n",
    "                    img_compare_two = cv2.cvtColor(np.float32(img_compare), cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    s = ssim(img_compare_one, img_compare_two)\n",
    "                    # s2 = sam(img_compare_one, img_compare_two)\n",
    "                    # s3 = sre(img_compare_one, img_compare_two)\n",
    "\n",
    "                    ssim_matrix[i,j] = s\n",
    "                    # sam_matrix[i,j] = s2\n",
    "                    # sre_matrix[i,j] = s3\n",
    "                    \n",
    "                    # releasing object\n",
    "                    del img_compare_one\n",
    "                    del img_compare_two\n",
    "                    \n",
    "                else:\n",
    "                    # resize image to match\n",
    "                    imgA, imgB = match_size(img_base, img_compare)\n",
    "                    \n",
    "                    #print('Size A: W:' + str(imgA.size[0]) + 'H: ' + str(imgA.size[1]))\n",
    "                    #print('Size B: W:' + str(imgB.size[0]) + 'H: ' + str(imgB.size[1]))\n",
    "                    \n",
    "                    if(imgA.size[0]*imgA.size[1] == imgB.size[0]*imgB.size[1]):\n",
    "                        img_compare_one = cv2.cvtColor(np.float32(imgA), cv2.COLOR_BGR2GRAY)\n",
    "                        img_compare_two = cv2.cvtColor(np.float32(imgB), cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                        s = ssim(img_compare_one, img_compare_two)\n",
    "                        # s2 = sam(img_compare_one, img_compare_two)\n",
    "                        # s3 = sre(img_compare_one, img_compare_two)\n",
    "                        \n",
    "                        ssim_matrix[i,j] = s\n",
    "                        # sam_matrix[i,j] = s2\n",
    "                        # sre_matrix[i,j] = s3\n",
    "                        \n",
    "                        # releasing object\n",
    "                        del img_compare_one\n",
    "                        del img_compare_two\n",
    "                        del imgA\n",
    "                        del imgB\n",
    "                    else:\n",
    "                        ssim_matrix[i,j] = 0.0\n",
    "                    \n",
    "                pbar.update(1)\n",
    "            # if (j<i):\n",
    "        # for i in range(0,len(df)):\n",
    "        # selesai satu baris\n",
    "    # for j in range(0, len(df)):\n",
    "    # selesai satu kolom\n",
    "    # check for any cluster info at this column\n",
    "    \n",
    "#with tqdm(total=( (len(df)*len(df)/2))-(len(df)/2))  as pbar:\n",
    "            \n",
    "                 \n",
    "pbar.close()\n",
    "print(ssim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import asarray\n",
    "# from numpy import savetxt\n",
    "\n",
    "# savetxt('data.csv', ssim_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-river",
   "metadata": {},
   "source": [
    "## SSIM Matrix Analysis\n",
    "Goals :\n",
    "- create base-tweet\n",
    "- create cluster result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-association",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "largest_s = 0.0\n",
    "\n",
    "#create zero element array\n",
    "#col 0 => index base tweet\n",
    "#col 1 => cluster number\n",
    "#col 2 => similarity score\n",
    "base_tweet = []\n",
    "\n",
    "#initial cluster number\n",
    "i_current_cluster = 0\n",
    "\n",
    "for j in range(0, len(ssim_matrix)):\n",
    "    largest_s = largest_in_col(ssim_matrix,j)\n",
    "    if (largest_s[0] > similarity_treshold):\n",
    "        print('largest s-index in column ' + str(j) + ' is: ' \\\n",
    "              + str(largest_s[0]) + \\\n",
    "              ' on rows# ' + str(largest_s[1]))\n",
    "        \n",
    "        # cari di baris yang kolomnya ini, untuk baris < kolom skrg\n",
    "        largest_s_row = largest_in_row(ssim_matrix,j)\n",
    "        print('largest s-index in row ' + str(j) + ' is: ' \\\n",
    "              + str(largest_s_row[0]) + \\\n",
    "              ' on col# ' + str(largest_s_row[1]))\n",
    "        \n",
    "        if (largest_s_row[0] < j):\n",
    "            if (largest_s_row[0] < similarity_treshold):\n",
    "                # add new cluster index\n",
    "                # print('tambah')\n",
    "                print(similarity_treshold)\n",
    "                i_current_cluster = i_current_cluster + 1\n",
    "                base_tweet.append([j,i_current_cluster,largest_s[0]])\n",
    "            \n",
    "# print(base_tweet)\n",
    "# append base 0\n",
    "base_tweet.append([0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_max = 0.0\n",
    "base_now = 0.0\n",
    "base_index = 0\n",
    "cluster_no = 0\n",
    "base_content = 0\n",
    "\n",
    "#create zero element array\n",
    "#col 0 => tweet id\n",
    "#col 1 => cluster no\n",
    "cluster_result = []\n",
    "\n",
    "for j in range(0, len(ssim_matrix)):\n",
    "    # compare to base tweet\n",
    "    # print('baris: ' + str(j))\n",
    "    \n",
    "    # cari nilai paling tinggi dari 3 base tweet\n",
    "    for val in base_tweet:\n",
    "        # print('sim index kolom: '+ str(val[0]) + ' adalah: ' + str(ssim_matrix[j,val[0]]))\n",
    "        base_now = ssim_matrix[j,val[0]]\n",
    "        if base_now > base_max:\n",
    "            base_max = base_now\n",
    "            base_index = val[0]\n",
    "            cluster_no = val[1]\n",
    "    \n",
    "    if(base_max > similarity_treshold):\n",
    "        # print('max dari baris: ' + str(j) + ' adalah: ' + str(base_max) + ' pada index: ' + str(cluster_no))\n",
    "        ## append to cluster-result\n",
    "        cluster_result.append([df['tweet_id'][j], cluster_no])\n",
    "    else:        \n",
    "        # jika ada dalam base-tweet, masukin sebagai cluster\n",
    "        base_content = 0\n",
    "        for val in base_tweet:\n",
    "            if(j == val[0]):\n",
    "                # insert as cluster\n",
    "                cluster_result.append([df['tweet_id'][j], val[1]])\n",
    "                # markdown as base\n",
    "                base_content = 1\n",
    "                \n",
    "        # non cluster\n",
    "        if(base_content == 0):\n",
    "            cluster_result.append([df['tweet_id'][j], 0])\n",
    "    \n",
    "    # reset base_max\n",
    "    base_max = 0\n",
    "    base_index = 0\n",
    "    cluster_no = 0\n",
    "\n",
    "# print(cluster_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save cluster result and base_tweet\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "\n",
    "savetxt('cluster_result.csv', cluster_result, delimiter=',')\n",
    "savetxt('base_tweet.csv', base_tweet, delimiter=',')\n",
    "\n",
    "# for i in range(0, len(df)):\n",
    "#     imgUrl = \"https://cekmedsos.com/uploads/twimg/\" + df['filename'][i]\n",
    "#     print(imgUrl)\n",
    "#     # loads this images\n",
    "#     img_base = Image.open(requests.get(imgUrl, stream=True).raw)\n",
    "#     # img_base = cv2.imread(requests.get(imgUrl, stream=True).raw)\n",
    "#     img_base.save(str(i) + '.jpg',\"PNG\")\n",
    "    \n",
    "# # (score, diff) = compare_images(original, shopped, 'Original vs Shopped')\n",
    "\n",
    "# (score,diff) = ssim(original, shopped, full=True)\n",
    "# diff = (diff * 255).astype(\"uint8\")\n",
    "# print(\"SSIM: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-photography",
   "metadata": {},
   "source": [
    "### Inserting to database\n",
    "\n",
    "1. Base Tweet\n",
    "2. Cluster Result\n",
    "3. Record Processing Time\n",
    "4. Marking as finished Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-beast",
   "metadata": {},
   "source": [
    "### 1. Base tweet insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#\n",
    "# Create Base Tweet Record\n",
    "sql = \"insert into ret_base_tweet (job_id, tweet_id, cluster_id) values (%s, %s, %s)\"\n",
    "\n",
    "## inserting base taweet\n",
    "for i in range(0,len(base_tweet)):\n",
    "    # Execute the query\n",
    "    if ( base_tweet[i][0] == 0):\n",
    "         #print(sql,          (i_process_id, 0, base_tweet[i][1]))   \n",
    "         cursor.execute(sql, (i_process_id, 0, base_tweet[i][1]))\n",
    "    else:\n",
    "         cursor.execute(sql, (i_process_id, df['tweet_id'][base_tweet[i][0]], base_tweet[i][1]))\n",
    "         #print(sql,          (i_process_id, df['tweet_id'][base_tweet[i][0]], base_tweet[i][1]))\n",
    "    \n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print('finished inserting base tweet record')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-powell",
   "metadata": {},
   "source": [
    "### 2. Cluster Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#\n",
    "# Create Base Tweet Record\n",
    "sql = \"insert into ret_cluster_result (job_id, tweet_id, cluster_no) values (%s, %s, %s)\"\n",
    "\n",
    "## inserting base taweet\n",
    "for i in range(0,len(cluster_result)):\n",
    "    # Execute the query\n",
    "    cursor.execute(sql, (i_process_id, cluster_result[i][0], cluster_result[i][1]))\n",
    "    # cluster_result[i][0]\n",
    "    # print(sql,          (i_process_id, cluster_result[i][0], cluster_result[i][1]))\n",
    "    \n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print('finished inserting base tweet record')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-automation",
   "metadata": {},
   "source": [
    "### 3. Record Processing Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#\n",
    "# Create Parameter Record\n",
    "sql = \"insert into ret_analysis_parameter (job_id, param_id, param_name, param_value) values (%s, %s, %s, %s)\"\n",
    "# Execute the query\n",
    "cursor.execute(sql, (i_process_id, 1, '#Tweet Processed',len(df)))\n",
    "\n",
    "#\n",
    "# Create Tweet Cluster Record\n",
    "sql = \"update ret_analysis_header set datetime_finish = %s where job_id = %s\"\n",
    "\n",
    "# Executing query\n",
    "cursor.execute(sql, (datetime.now(),i_process_id) )\n",
    "\n",
    "print(i_process_id)\n",
    "\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print('job finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-rotation",
   "metadata": {},
   "source": [
    "### 4. Marking as finished Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='202.157.176.225',\n",
    "                             user='cekmedsos_db',\n",
    "                             password='kuku838485*#',\n",
    "                             database='cekmedsos_database',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# inserting jobs into table mv result\n",
    "# sql = \"call spInsertResultToMV(%s);\" \n",
    "\n",
    "# Executing query\n",
    "# cursor.execute(sql,i_process_id)\n",
    "\n",
    "sql = \"update screen_analisis_ai set processby_id = 1, status = 3, end_process = now(), duration = TIMESTAMPDIFF(second,start_process, end_process) where id = %s\"\n",
    "# Executing query\n",
    "cursor.execute(sql,i_process_id)\n",
    "\n",
    "# commit changes\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print('inserting result finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-phone",
   "metadata": {},
   "source": [
    "### Wait 10 sec before querying next jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait 10 sec before release\n",
    "time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
